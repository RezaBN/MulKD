{"cells":[{"cell_type":"code","source":["# main.py\n","\"\"\"\n","Main orchestration script for the MulKD CIFAR-10 evaluation.\n","This script imports components from other modules and runs the full\n","training and evaluation pipeline for teachers and students.\n","\"\"\"\n","\n","import os\n","import time\n","from collections import OrderedDict\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# --- Local Imports ---\n","import config\n","from data import get_cifar10_dataloaders\n","from models import (ResNet110_cifar, ResNet56_cifar, ResNet50_cifar_approx,\n","                    ResNet44_cifar, ResNet38_cifar, ResNet32_cifar,\n","                    ResNet20_cifar, ResNet8_cifar, MobileNetV2_paper,\n","                    ShuffleNetV2_paper, _get_penultimate_dim)\n","from losses import CRDLoss\n","from utils import train_one_epoch, test_model, adjust_learning_rate\n","from plotting import (plot_training_progress, plot_confusion_matrix,\n","                      print_summary_table, plot_student_model_comparison)\n","\n","# --- Orchestration Helpers ---\n","\n","def train_and_evaluate_scenario(model_key, model_instance, trainloader, testloader,\n","                                criterion_ce, num_epochs, initial_lr, lr_decay_epochs,\n","                                lr_decay_rate, distill_config, results_dict, model_paths,\n","                                plot_path, teacher_single=None, teacher_ensemble=None):\n","    \"\"\"High-level wrapper for training and evaluating a single model configuration.\"\"\"\n","    scenario_start_time = time.time()\n","    print(f\"\\n===== Scenario: {model_key} (Epochs: {num_epochs}) =====\")\n","\n","    model_instance.to(config.DEVICE)\n","    optimizer = optim.SGD(model_instance.parameters(), lr=initial_lr, momentum=config.MOMENTUM, weight_decay=config.WEIGHT_DECAY)\n","\n","    # Setup CRD loss if applicable\n","    crd_loss_instance = None\n","    run_distill_config = distill_config.copy()\n","    if run_distill_config['lambda_crd'] > 0:\n","        s_dim = _get_penultimate_dim(model_instance, config.DEVICE)\n","        teacher_for_probe = teacher_single or (teacher_ensemble[0] if teacher_ensemble else None)\n","        t_dim = _get_penultimate_dim(teacher_for_probe, config.DEVICE) if teacher_for_probe else 0\n","\n","        if t_dim > 0 and s_dim > 0:\n","            crd_params = type('Opt', (), {\n","                's_dim': s_dim, 't_dim': t_dim,\n","                'feat_dim': run_distill_config['crd_feat_dim'],\n","                'nce_t': run_distill_config['crd_nce_t'],\n","                'nce_n': run_distill_config['crd_num_negatives']\n","            })()\n","            crd_loss_instance = CRDLoss(crd_params).to(config.DEVICE)\n","            print(f\"CRD Enabled. S_dim:{s_dim}, T_dim:{t_dim}\")\n","        else:\n","            print(f\"Warning: CRD disabled for {model_key} due to missing feature dims.\")\n","            run_distill_config['lambda_crd'] = 0.0\n","\n","    # Check for and load existing checkpoints\n","    model_save_path = model_paths[model_key]\n","    start_epoch, best_acc, cumulative_time = 0, 0.0, 0.0\n","    if os.path.exists(model_save_path):\n","        print(f\"Found checkpoint for {model_key} at {model_save_path}\")\n","        try:\n","            checkpoint = torch.load(model_save_path, map_location=config.DEVICE)\n","            model_instance.load_state_dict(checkpoint['state_dict'])\n","            ckpt_epochs = checkpoint.get('epoch', 0)\n","\n","            # Resume if the checkpoint was for the same number of total epochs\n","            if checkpoint.get('config_epochs') == num_epochs and ckpt_epochs < num_epochs:\n","                start_epoch = ckpt_epochs\n","                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","                best_acc = checkpoint.get('best_acc', 0.0)\n","                cumulative_time = checkpoint.get('cumulative_training_time_seconds', 0.0)\n","                print(f\"Resuming training from epoch {start_epoch + 1}/{num_epochs}.\")\n","            else:\n","                print(\"Checkpoint is for a different configuration or is already complete. Evaluating as is.\")\n","                start_epoch = num_epochs # Skip training\n","        except Exception as e:\n","            print(f\"Error loading checkpoint: {e}. Starting fresh.\")\n","\n","    # Main training loop\n","    if start_epoch < num_epochs:\n","        training_history = {'total_loss': [], 'test_acc': [], 'ce_loss': [], 'kd_loss': [], 'crd_loss': []}\n","        current_run_start_time = time.time()\n","        for epoch in range(start_epoch, num_epochs):\n","            adjust_learning_rate(optimizer, epoch, initial_lr, lr_decay_epochs, lr_decay_rate)\n","\n","            loss, acc_train, ce, kd, crd = train_one_epoch(\n","                epoch, num_epochs, model_instance, trainloader, optimizer, criterion_ce,\n","                run_distill_config, teacher_single, teacher_ensemble, crd_loss_instance\n","            )\n","            training_history['total_loss'].append(loss); training_history['ce_loss'].append(ce)\n","            training_history['kd_loss'].append(kd); training_history['crd_loss'].append(crd)\n","\n","            acc_test, _, _, _ = test_model(epoch, model_instance, testloader, criterion_ce, model_key)\n","            training_history['test_acc'].append(acc_test)\n","\n","            if acc_test > best_acc:\n","                best_acc = acc_test\n","                total_time = cumulative_time + (time.time() - current_run_start_time)\n","                print(f\"Saving new best model for {model_key} (Epoch {epoch+1}, Acc: {best_acc:.2f}%)\")\n","                torch.save({\n","                    'state_dict': model_instance.state_dict(),\n","                    'optimizer_state_dict': optimizer.state_dict(),\n","                    'best_acc': best_acc, 'epoch': epoch + 1,\n","                    'config_epochs': num_epochs,\n","                    'cumulative_training_time_seconds': total_time\n","                }, model_save_path)\n","        plot_training_progress(training_history, model_key, plot_path, num_epochs)\n","\n","    # Final evaluation using the best saved model\n","    print(f\"Reloading best model for {model_key} for final evaluation.\")\n","    final_acc, final_time = 0.0, 0.0\n","    if os.path.exists(model_save_path):\n","        best_checkpoint = torch.load(model_save_path, map_location=config.DEVICE)\n","        model_instance.load_state_dict(best_checkpoint['state_dict'])\n","        final_acc = best_checkpoint.get('best_acc', 0.0)\n","        final_time = best_checkpoint.get('cumulative_training_time_seconds', 0.0)\n","\n","        _, _, y_true, y_pred = test_model(-1, model_instance, testloader, criterion_ce, f\"Final Best {model_key}\")\n","        plot_confusion_matrix(y_true, y_pred, config.CIFAR10_CLASSES, model_key, plot_path, f\" (Epochs {num_epochs})\")\n","\n","    results_dict[model_key] = {'acc': final_acc, 'time': final_time, 'epochs': num_epochs}\n","    print(f\"Scenario {model_key} complete. Final Best Acc: {final_acc:.2f}%, Time: {final_time:.2f}s\")\n","    print(f\"Total time for scenario: {time.time() - scenario_start_time:.2f}s\")\n","    return model_instance\n","\n","def load_completed_model(model_key, constructor, model_path, testloader, criterion, results, plot_path, epochs):\n","    \"\"\"Loads a pre-trained model, evaluates it, and populates results.\"\"\"\n","    print(f\"\\n===== Loading Completed Model: {model_key} =====\")\n","    model = constructor().to(config.DEVICE)\n","    acc, train_time = 0.0, 0.0\n","    if os.path.exists(model_path):\n","        try:\n","            ckpt = torch.load(model_path, map_location=config.DEVICE)\n","            model.load_state_dict(ckpt['state_dict'])\n","            acc = ckpt.get('best_acc', 0.0)\n","            train_time = ckpt.get('cumulative_training_time_seconds', 0.0)\n","            print(f\"Loaded {model_key}. Stored Acc: {acc:.2f}%. Re-evaluating...\")\n","            _, _, y_true, y_pred = test_model(-1, model, testloader, criterion, f\"Loaded {model_key}\")\n","            plot_confusion_matrix(y_true, y_pred, config.CIFAR10_CLASSES, model_key, plot_path, f\" (Epochs {epochs})\")\n","        except Exception as e:\n","            print(f\"Error loading {model_key}: {e}\")\n","    else:\n","        print(f\"Checkpoint for {model_key} NOT FOUND at {model_path}.\")\n","\n","    results[model_key] = {'acc': acc, 'time': train_time, 'epochs': epochs}\n","    return model\n","\n","# --- Main Execution ---\n","def run_mulkd_cifar10_evaluation():\n","    \"\"\"Main function to run the entire evaluation pipeline.\"\"\"\n","    script_start_time = time.time()\n","    print(f\"Using device: {config.DEVICE}\")\n","\n","    # Setup directories\n","    base_path = config.GDRIVE_BASE_PATH\n","    model_dir = os.path.join(base_path, f\"models_{int(config.DATASET_SUBSET_FRACTION*100)}pct\")\n","    plot_dir = os.path.join(base_path, f\"plots_{int(config.DATASET_SUBSET_FRACTION*100)}pct\")\n","    os.makedirs(model_dir, exist_ok=True)\n","    os.makedirs(plot_dir, exist_ok=True)\n","    print(f\"Models will be saved in: {model_dir}\")\n","    print(f\"Plots will be saved in: {plot_dir}\")\n","\n","    # Load data\n","    trainloader, testloader = get_cifar10_dataloaders(config.BATCH_SIZE, config.DATASET_SUBSET_FRACTION)\n","    if not trainloader or not testloader:\n","        print(\"Error: Dataloaders are empty. Exiting.\")\n","        return\n","\n","    criterion_ce = nn.CrossEntropyLoss()\n","    results = OrderedDict()\n","\n","    # Define model paths and constructors\n","    model_keys = [\n","        \"Grandmaster_ResNet110_S\", \"TA1_L1_ResNet56_S\", \"TA1_L1_ResNet56_M\",\n","        \"TA2_L1_ResNet50_S\", \"TA2_L1_ResNet50_M\", \"Master_ResNet44_S\", \"Master_ResNet44_M\",\n","        \"TA1_L2_ResNet38_S\", \"TA1_L2_ResNet38_M\", \"TA2_L2_ResNet32_S\", \"TA2_L2_ResNet32_M\",\n","        \"CM_ResNet20_S\", \"CM_ResNet20_M\", \"Student_ResNet8_S\", \"Student_ResNet8_M_from_Master\",\n","        \"Student_ResNet8_M_from_CM\", \"Student_MobileNetV2_S\", \"Student_MobileNetV2_M_from_Master\",\n","        \"Student_MobileNetV2_M_from_CM\", \"Student_ShuffleNetV2_S\", \"Student_ShuffleNetV2_M_from_Master\",\n","        \"Student_ShuffleNetV2_M_from_CM\"\n","    ]\n","    model_paths = {k: os.path.join(model_dir, f\"{k.lower()}.pth\") for k in model_keys}\n","    constructors = {\n","        \"Grandmaster_ResNet110\": ResNet110_cifar, \"TA1_L1_ResNet56\": ResNet56_cifar,\n","        \"TA2_L1_ResNet50\": ResNet50_cifar_approx, \"Master_ResNet44\": ResNet44_cifar,\n","        \"TA1_L2_ResNet38\": ResNet38_cifar, \"TA2_L2_ResNet32\": ResNet32_cifar,\n","        \"CM_ResNet20\": ResNet20_cifar, \"Student_ResNet8\": ResNet8_cifar,\n","        \"Student_MobileNetV2\": MobileNetV2_paper, \"Student_ShuffleNetV2\": ShuffleNetV2_paper\n","    }\n","\n","    # --- Teacher Training/Loading ---\n","    teacher_epochs = config.EPOCHS_TEACHER_CIFAR10\n","    teacher_lr_decay = config.LR_DECAY_EPOCHS_160_CIFAR10\n","\n","    # This list determines which models to load vs. train. Comment out to force re-training.\n","    COMPLETED_KEYS = [\n","        \"Grandmaster_ResNet110_S\", \"TA1_L1_ResNet56_M\", \"TA2_L1_ResNet50_M\",\n","        \"Master_ResNet44_M\", \"TA1_L2_ResNet38_M\", \"TA2_L2_ResNet32_M\", \"CM_ResNet20_M\"\n","    ]\n","\n","    def run_or_load(key, constructor, is_mulkd, teacher=None, ensemble=None):\n","        if key in COMPLETED_KEYS and os.path.exists(model_paths[key]):\n","            return load_completed_model(key, constructor, model_paths[key], testloader, criterion_ce, results, plot_dir, teacher_epochs)\n","\n","        lr = config.LR_RESNET_CIFAR10\n","        dist_cfg = config.distill_config_mulkd if is_mulkd else config.distill_config_scratch\n","        return train_and_evaluate_scenario(key, constructor(), trainloader, testloader, criterion_ce,\n","                                           teacher_epochs, lr, teacher_lr_decay, config.LR_DECAY_RATE,\n","                                           dist_cfg, results, model_paths, plot_dir, teacher, ensemble)\n","\n","    gm = run_or_load(\"Grandmaster_ResNet110_S\", constructors[\"Grandmaster_ResNet110\"], False)\n","    ta1_l1 = run_or_load(\"TA1_L1_ResNet56_M\", constructors[\"TA1_L1_ResNet56\"], True, teacher=gm)\n","    ta2_l1 = run_or_load(\"TA2_L1_ResNet50_M\", constructors[\"TA2_L1_ResNet50\"], True, teacher=gm)\n","    master = run_or_load(\"Master_ResNet44_M\", constructors[\"Master_ResNet44\"], True, ensemble=[ta1_l1, ta2_l1])\n","    ta1_l2 = run_or_load(\"TA1_L2_ResNet38_M\", constructors[\"TA1_L2_ResNet38\"], True, teacher=master)\n","    ta2_l2 = run_or_load(\"TA2_L2_ResNet32_M\", constructors[\"TA2_L2_ResNet32\"], True, teacher=master)\n","    cm = run_or_load(\"CM_ResNet20_M\", constructors[\"CM_ResNet20\"], True, ensemble=[ta1_l2, ta2_l2])\n","\n","    # --- Student Training ---\n","    student_epochs = config.EPOCHS_STUDENT_CIFAR10\n","    student_lr_decay = config.LR_DECAY_EPOCHS_100_CIFAR10\n","    student_configs = [(\"ResNet8\", config.LR_RESNET_CIFAR10),\n","                       (\"MobileNetV2\", config.LR_LIGHTWEIGHT_CIFAR10),\n","                       (\"ShuffleNetV2\", config.LR_LIGHTWEIGHT_CIFAR10)]\n","\n","    for name, lr in student_configs:\n","        const_key = f\"Student_{name}\"\n","        # From scratch\n","        train_and_evaluate_scenario(f\"Student_{name}_S\", constructors[const_key](), trainloader, testloader, criterion_ce,\n","                                    student_epochs, lr, student_lr_decay, config.LR_DECAY_RATE,\n","                                    config.distill_config_scratch, results, model_paths, plot_dir)\n","        # From Master\n","        train_and_evaluate_scenario(f\"Student_{name}_M_from_Master\", constructors[const_key](), trainloader, testloader, criterion_ce,\n","                                    student_epochs, lr, student_lr_decay, config.LR_DECAY_RATE,\n","                                    config.distill_config_mulkd, results, model_paths, plot_dir, teacher_single=master)\n","        # From CM\n","        train_and_evaluate_scenario(f\"Student_{name}_M_from_CM\", constructors[const_key](), trainloader, testloader, criterion_ce,\n","                                    student_epochs, lr, student_lr_decay, config.LR_DECAY_RATE,\n","                                    config.distill_config_mulkd, results, model_paths, plot_dir, teacher_single=cm)\n","\n","    # --- Final Reporting ---\n","    print_summary_table(results, student_configs)\n","    plot_student_model_comparison(results, student_configs, plot_dir, student_epochs)\n","\n","    total_time = time.time() - script_start_time\n","    print(f\"\\nTotal Run Time: {total_time/3600:.2f} hours.\")\n","    print(\"MulKD CIFAR-10 Evaluation Run Complete!\")\n","\n","if __name__ == '__main__':\n","    run_mulkd_cifar10_evaluation()"],"outputs":[],"execution_count":null,"metadata":{"id":"I5rw9gHTDYm5"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
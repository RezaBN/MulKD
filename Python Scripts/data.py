{"cells":[{"cell_type":"code","source":["# data.py\n","\"\"\"\n","This file contains the function for loading and preparing the CIFAR-10 dataset,\n","including support for using a random subset of the data.\n","\"\"\"\n","\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np\n","\n","# Import from local modules\n","from config import CIFAR10_MEAN, CIFAR10_STD\n","\n","def get_cifar10_dataloaders(batch_size_dl, subset_fraction=1.0, num_workers=2):\n","    \"\"\"\n","    Loads CIFAR-10 train and test datasets.\n","    If subset_fraction < 1.0, it loads a random subset of the data.\n","    \"\"\"\n","    print(f\"\\n--- Loading CIFAR-10 Data (Subset: {subset_fraction*100:.0f}%) ---\")\n","\n","    # Data augmentation and normalization for training\n","    transform_train = transforms.Compose([\n","        transforms.RandomCrop(32, padding=4),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD)\n","    ])\n","\n","    # Normalization for testing\n","    transform_test = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD)\n","    ])\n","\n","    # Download or load the full datasets\n","    full_trainset = torchvision.datasets.CIFAR10(\n","        root='./data_cifar10', train=True, download=True, transform=transform_train\n","    )\n","    full_testset = torchvision.datasets.CIFAR10(\n","        root='./data_cifar10', train=False, download=True, transform=transform_test\n","    )\n","\n","    if subset_fraction < 1.0:\n","        print(f\"Using {subset_fraction*100:.0f}% of the CIFAR-10 dataset.\")\n","\n","        # Create a random subset of the training set\n","        num_train = len(full_trainset)\n","        train_indices = list(range(num_train))\n","        np.random.shuffle(train_indices)\n","        split_train = int(np.floor(subset_fraction * num_train))\n","        subset_train_indices = train_indices[:split_train]\n","        trainset = torch.utils.data.Subset(full_trainset, subset_train_indices)\n","        print(f\"Training on {len(trainset)}/{num_train} samples.\")\n","\n","        # Create a random subset of the test set\n","        num_test = len(full_testset)\n","        test_indices = list(range(num_test))\n","        np.random.shuffle(test_indices)\n","        split_test = int(np.floor(subset_fraction * num_test))\n","        subset_test_indices = test_indices[:split_test]\n","        testset = torch.utils.data.Subset(full_testset, subset_test_indices)\n","        print(f\"Testing on {len(testset)}/{num_test} samples.\")\n","    else:\n","        print(\"Using the full CIFAR-10 dataset.\")\n","        trainset = full_trainset\n","        testset = full_testset\n","        print(f\"Training on {len(trainset)} samples.\")\n","        print(f\"Testing on {len(testset)} samples.\")\n","\n","    # Create data loaders\n","    trainloader = torch.utils.data.DataLoader(\n","        trainset, batch_size=batch_size_dl, shuffle=True, num_workers=num_workers, pin_memory=True\n","    )\n","    testloader = torch.utils.data.DataLoader(\n","        testset, batch_size=batch_size_dl, shuffle=False, num_workers=num_workers, pin_memory=True\n","    )\n","\n","    print(\"--- Data Loading Complete ---\")\n","    return trainloader, testloader"],"outputs":[],"execution_count":null,"metadata":{"id":"mXpnSsnaBpTX"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
{"cells":[{"cell_type":"code","source":["# models.py\n","\"\"\"\n","This file contains all model architecture definitions, including ResNets for CIFAR-10\n","and lightweight models like MobileNetV2 and ShuffleNetV2. It also includes helper\n","functions to extract outputs and feature dimensions from these models.\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","\n","# --- ResNet Architectures (for CIFAR) ---\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion * planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion * planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10, in_channels=3):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 16\n","\n","        self.conv1 = nn.Conv2d(in_channels, 16, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(16)\n","\n","        # This implementation is specific to CIFAR-style ResNets with 3 stages\n","        if len(num_blocks) == 3:\n","            self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n","            self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n","            self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n","            self.penultimate_dim = 64 * block.expansion\n","        else:\n","             raise ValueError(\"num_blocks for CIFAR ResNet should be a list of 3 integers\")\n","\n","        self.linear = nn.Linear(self.penultimate_dim, num_classes)\n","        # Add a flag to indicate native support for returning features\n","        self.supports_return_features = True\n","\n","    def _make_layer(self, block, planes, num_blocks_in_stage, stride):\n","        strides = [stride] + [1] * (num_blocks_in_stage - 1)\n","        layers = []\n","        for s_val in strides:\n","            layers.append(block(self.in_planes, planes, s_val))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x, return_features=False):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","\n","        pool_size = out.shape[-1] # Adaptive pooling based on feature map size\n","        features_for_crd = F.avg_pool2d(out, kernel_size=pool_size)\n","        features_for_crd = features_for_crd.view(features_for_crd.size(0), -1)\n","\n","        logits = self.linear(features_for_crd)\n","\n","        return (logits, features_for_crd) if return_features else logits\n","\n","# --- ResNet Factory Functions ---\n","def ResNet8_cifar(num_classes=10): return ResNet(BasicBlock, [1, 1, 1], num_classes)\n","def ResNet20_cifar(num_classes=10): return ResNet(BasicBlock, [3, 3, 3], num_classes)\n","def ResNet32_cifar(num_classes=10): return ResNet(BasicBlock, [5, 5, 5], num_classes)\n","def ResNet38_cifar(num_classes=10): return ResNet(BasicBlock, [6, 6, 6], num_classes)\n","def ResNet44_cifar(num_classes=10): return ResNet(BasicBlock, [7, 7, 7], num_classes)\n","def ResNet50_cifar_approx(num_classes=10): return ResNet(BasicBlock, [8, 8, 8], num_classes)\n","def ResNet56_cifar(num_classes=10): return ResNet(BasicBlock, [9, 9, 9], num_classes)\n","def ResNet110_cifar(num_classes=10): return ResNet(BasicBlock, [18, 18, 18], num_classes)\n","\n","\n","# --- Lightweight Models ---\n","def MobileNetV2_paper(num_classes=10, pretrained=False):\n","    model = torchvision.models.mobilenet_v2(weights=torchvision.models.MobileNet_V2_Weights.IMAGENET1K_V1 if pretrained else None)\n","    model.classifier[1] = nn.Linear(model.last_channel, num_classes)\n","    model.supports_return_features = False # Handled by get_model_output\n","    model.penultimate_dim = model.last_channel\n","    return model\n","\n","def ShuffleNetV2_paper(num_classes=10, pretrained=False):\n","    model = torchvision.models.shufflenet_v2_x1_0(weights=torchvision.models.ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1 if pretrained else None)\n","    original_fc_in_features = model.fc.in_features\n","    model.fc = nn.Linear(original_fc_in_features, num_classes)\n","    model.penultimate_dim = original_fc_in_features\n","    model.supports_return_features = False # Handled by get_model_output\n","    return model\n","\n","\n","# --- Model Output Helpers ---\n","def get_model_output(model, inputs, for_crd=False):\n","    \"\"\"\n","    A unified function to get logits and feature representations from any model.\n","    This handles differences between custom ResNets and torchvision models.\n","    \"\"\"\n","    logits, features = None, None\n","\n","    if hasattr(model, 'supports_return_features') and model.supports_return_features:\n","        # This branch is for our custom ResNet models\n","        logits, features = model(inputs, return_features=True)\n","\n","    elif isinstance(model, torchvision.models.MobileNetV2):\n","        # Specific handling for torchvision MobileNetV2\n","        extracted_feats_module = model.features(inputs)\n","        # Global average pooling before the classifier\n","        features = F.adaptive_avg_pool2d(extracted_feats_module, (1, 1)).reshape(extracted_feats_module.shape[0], -1)\n","        logits = model.classifier(features)\n","\n","    elif isinstance(model, torchvision.models.ShuffleNetV2):\n","        # Specific handling for torchvision ShuffleNetV2\n","        x = model.conv1(inputs); x = model.maxpool(x); x = model.stage2(x)\n","        x = model.stage3(x); x = model.stage4(x)\n","        extracted_feats_module = model.conv5(x)\n","        features = extracted_feats_module.mean([2, 3]) # Global average pooling\n","        logits = model.fc(features)\n","\n","    else:\n","        # Fallback for other models, may not provide features for CRD\n","        logits = model(inputs)\n","        if for_crd:\n","            print(f\"Warning: CRD features requested but not explicitly extracted for {type(model).__name__}. Features will be None.\")\n","\n","    return logits, features\n","\n","\n","def _get_penultimate_dim(model_instance, device_to_use):\n","    \"\"\"\n","    Dynamically determines the dimension of the feature vector before the final classifier.\n","    Caches the result in the model instance.\n","    \"\"\"\n","    # Return cached dimension if it exists\n","    if hasattr(model_instance, 'penultimate_dim') and model_instance.penultimate_dim > 0:\n","        return model_instance.penultimate_dim\n","\n","    # Ensure model is on the correct device and in eval mode for probing\n","    model_instance.to(device_to_use)\n","    original_mode_is_training = model_instance.training\n","    model_instance.eval()\n","    dim = 0\n","\n","    with torch.no_grad():\n","        # Create a dummy input typical for CIFAR-10\n","        dummy_input = torch.randn(1, 3, 32, 32).to(device_to_use)\n","        _, features = get_model_output(model_instance, dummy_input, for_crd=True)\n","        if features is not None:\n","            dim = features.shape[1]\n","        else:\n","            print(f\"Warning: _get_penultimate_dim: features were None for {type(model_instance).__name__}.\")\n","\n","    # Restore original mode\n","    if original_mode_is_training:\n","        model_instance.train()\n","\n","    # Cache the dimension in the model instance for future use\n","    model_instance.penultimate_dim = dim\n","\n","    if dim == 0:\n","        print(f\"Warning: _get_penultimate_dim resulted in 0 for {type(model_instance).__name__}. CRD might fail.\")\n","\n","    return dim"],"outputs":[],"execution_count":null,"metadata":{"id":"H9Ju3lI6BwUx"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}